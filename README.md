# Motion Classifier Model ğŸ¤–

## Autores âœ’ï¸

> - Juan David Colonia Aldana - A00395956
> - Miguel Angel Gonzalez Arango - A00395687
> - Pablo Fernando Pineda PatiÃ±o - A00395831

## Videos ğŸ’¾

### [Data](https://icesiedu-my.sharepoint.com/:f:/g/personal/1105929455_u_icesi_edu_co/EnzCUqohRKJHkpldjByJuBMBwwkLNHv5qPzTzO7s-tlBMw?e=tvTkC7)

## ğŸ“‹ DescripciÃ³n

Esta aplicaciÃ³n web integra detecciÃ³n de poses en tiempo real con clasificaciÃ³n de movimientos corporales usando machine learning. Combina MediaPipe para la detecciÃ³n de landmarks con un modelo entrenado para clasificar 5 tipos de movimientos:

- **girar** - Movimientos de rotaciÃ³n
- **sentar** - AcciÃ³n de sentarse
- **parar** - PosiciÃ³n de pie/parada
- **ir al frente** - Movimiento hacia adelante
- **devolverse** - Movimiento hacia atrÃ¡s

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Servidor Web  â”‚    â”‚   API Modelo    â”‚
â”‚   (HTML/JS/CSS) â”‚â—„â”€â”€â–ºâ”‚   (server.py)   â”‚â—„â”€â”€â–ºâ”‚  (model_api.py) â”‚
â”‚                 â”‚    â”‚   Puerto 8000   â”‚    â”‚   Puerto 5000   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                              â”‚
        â–¼                                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MediaPipe     â”‚                        â”‚   Modelo ML     â”‚
â”‚   (Poses)       â”‚                        â”‚   (XGBoost)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Inicio RÃ¡pido

### OpciÃ³n 1: Script AutomÃ¡tico (Recomendado)

```bash
python start.py
```

### OpciÃ³n 2: Manual

```bash
# 1. Instalar dependencias
pip install -r requirements.txt

# 2. Ejecutar servidor (inicia ambos: web + API)
python server.py
```

## ğŸ“ Estructura de Archivos

```
motion-classifier-model/
â”œâ”€â”€ ğŸŒ APLICACIÃ“N WEB
â”‚   â”œâ”€â”€ server.py              # Servidor principal (puerto 8000)
â”‚   â”œâ”€â”€ model_api.py           # API del modelo (puerto 5000)
â”‚   â”œâ”€â”€ index.html             # Interfaz web
â”‚   â”œâ”€â”€ script.js              # LÃ³gica frontend + integraciÃ³n ML
â”‚   â”œâ”€â”€ styles.css             # Estilos de la aplicaciÃ³n
â”‚   â””â”€â”€ start.py               # Script de inicio automÃ¡tico
â”‚
â”œâ”€â”€ ğŸ¤– MODELO ENTRENADO
â”‚   â””â”€â”€ notebooks/models/      # Archivos del modelo exportado
â”‚       â”œâ”€â”€ motion_classifier_*.joblib
â”‚       â”œâ”€â”€ scaler_*.joblib
â”‚       â”œâ”€â”€ label_encoder_*.joblib
â”‚       â”œâ”€â”€ feature_engineer_*.joblib
â”‚       â””â”€â”€ model_metadata_*.json
â”‚
â”œâ”€â”€ ğŸ“Š NOTEBOOKS DE DESARROLLO
â”‚   â”œâ”€â”€ notebooks/eda.ipynb           # AnÃ¡lisis exploratorio
â”‚   â””â”€â”€ notebooks/model_training.ipynb # Entrenamiento del modelo
â”‚
â”œâ”€â”€ ğŸ”§ CONFIGURACIÃ“N
â”‚   â”œâ”€â”€ requirements.txt        # Dependencias Python
â”‚   â””â”€â”€ README_WEB_INTEGRATION.md # Esta documentaciÃ³n
â”‚
â””â”€â”€ ğŸ“¹ PROCESAMIENTO DE DATOS
    â”œâ”€â”€ video_processing_mediapipe.py
    â”œâ”€â”€ combine_data.py
    â””â”€â”€ combined_dataset.csv
```

## ğŸ¯ Funcionalidades

### âœ… DetecciÃ³n de Poses

- **MediaPipe Pose**: DetecciÃ³n de 33 landmarks corporales
- **Tiempo Real**: Procesamiento en vivo desde la cÃ¡mara web
- **VisualizaciÃ³n**: Landmarks y conexiones superpuestas

### ğŸ¤– ClasificaciÃ³n de Movimientos

- **Modelo**: Entrenado con features geomÃ©tricas avanzadas
- **Features Engineered**: Ãngulos, distancias, proporciones corporales
- **PredicciÃ³n en Tiempo Real**: ClasificaciÃ³n cada 500ms
- **Confianza Visual**: Barra de confianza con colores

### ğŸ¨ Interfaz de Usuario

- **DiseÃ±o Moderno**: UI responsiva y atractiva
- **Estados Visuales**: Indicadores de estado del modelo y cÃ¡mara
- **Controles Intuitivos**: Botones para iniciar/detener
- **InformaciÃ³n en Tiempo Real**: FPS, estado del modelo, predicciones

## ğŸ”§ ConfiguraciÃ³n TÃ©cnica

### Dependencias Principales

```
mediapipe          # DetecciÃ³n de poses
opencv-python      # Procesamiento de video
scikit-learn       # Machine learning
xgboost           # Modelo de clasificaciÃ³n
flask             # API del modelo
flask-cors        # CORS para API
pandas            # ManipulaciÃ³n de datos
numpy             # Operaciones numÃ©ricas
```

### Puertos Utilizados

- **8000**: Servidor web principal (HTML/CSS/JS)
- **5000**: API del modelo de clasificaciÃ³n

### Endpoints de la API

```
GET  /health       # Estado del servidor y modelo
POST /predict      # Clasificar movimiento desde landmarks
GET  /model-info   # InformaciÃ³n detallada del modelo
```

## ğŸ“Š Pipeline de Procesamiento

```
1. ğŸ“¹ Captura de Video (CÃ¡mara Web)
   â†“
2. ğŸ” DetecciÃ³n de Poses (MediaPipe)
   â†“
3. ğŸ“ Feature Engineering (Ãngulos + Distancias)
   â†“
4. ğŸ¤– ClasificaciÃ³n ML (XGBoost)
   â†“
5. ğŸ“Š VisualizaciÃ³n (Canvas + Texto)
```

## ğŸ® Uso de la AplicaciÃ³n

1. **Iniciar**: Ejecuta `python start.py` o `python server.py`
2. **Navegador**: Ve a `http://localhost:8000`
3. **Permisos**: Permite acceso a la cÃ¡mara
4. **Activar**: Haz clic en "Iniciar CÃ¡mara"
5. **Movimientos**: Realiza movimientos frente a la cÃ¡mara
6. **Observar**: Ve las predicciones en tiempo real

## ğŸ” Indicadores Visuales

### Estados del Modelo

- âœ… **Verde**: Modelo cargado y funcionando
- âŒ **Rojo**: Modelo no disponible
- âš ï¸ **Amarillo**: Verificando estado

### Confianza de PredicciÃ³n

- ğŸŸ¢ **Verde** (>80%): Alta confianza
- ğŸŸ¡ **Amarillo** (60-80%): Confianza media
- ğŸŸ  **Naranja** (<60%): Baja confianza

### Estados de la CÃ¡mara

- ğŸ”´ **Desconectado**: CÃ¡mara no iniciada
- ğŸŸ¢ **Conectado**: CÃ¡mara activa y funcionando
- âš ï¸ **Error**: Problema de acceso a cÃ¡mara

## ğŸ”„ Flujo de Datos

```mermaid
graph TD
    A[CÃ¡mara Web] --> B[MediaPipe]
    B --> C[Landmarks 33 puntos]
    C --> D[Feature Engineering]
    D --> E[API Modelo /predict]
    E --> F[ClasificaciÃ³n XGBoost]
    F --> G[Resultado + Confianza]
    G --> H[VisualizaciÃ³n Canvas]

    I[Servidor Web :8000] --> J[HTML/CSS/JS]
    K[API Modelo :5000] --> L[Flask + ML Pipeline]
```

## ğŸ“ˆ Rendimiento

- **FPS**: ~15-30 FPS (dependiendo del hardware)
- **Latencia**: ~50-100ms por predicciÃ³n
- **PrecisiÃ³n**: Variable segÃºn calidad del modelo entrenado
- **Recursos**: Moderado uso de CPU, mÃ­nimo GPU

## ğŸ”® PrÃ³ximas Mejoras

- [ ] Historial de movimientos
- [ ] ExportaciÃ³n de datos de sesiÃ³n
- [ ] MÃºltiples modelos seleccionables
- [ ] CalibraciÃ³n de sensibilidad
- [ ] Modo de entrenamiento en vivo
- [ ] Soporte para mÃºltiples personas

---

## ğŸ¤ ContribuciÃ³n

Para contribuir al proyecto:

1. Fork el repositorio
2. Crea una rama para tu feature
3. Realiza tus cambios
4. EnvÃ­a un pull request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo licencia MIT. Ver archivo LICENSE para mÃ¡s detalles.
